{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290725f3",
   "metadata": {},
   "source": [
    "---\n",
    "title: S3 Data Upload and Download\n",
    "author: GSI Environmental Inc.\n",
    "date: 2025-11-17\n",
    "code-fold: false\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58416cbf",
   "metadata": {},
   "source": [
    "This page provides simple examples of how to upload and download Parquet files to and from an AWS S3 bucket using the Boto3 library in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5530b75",
   "metadata": {},
   "source": [
    "## Parquet Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05aea84",
   "metadata": {},
   "source": [
    "Note that in order to upload files to S3, you need to have AWS credentials configured. You can set up your credentials using the AWS CLI or by setting environment variables. This example assumes you have the necessary permissions to upload files to the specified S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6314de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "\n",
    "# AWS S3 configuration\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\", \"phyto-indicator\")\n",
    "AWS_S3_PREFIX = \"data/\"\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.parent / \"phyto-indicator-data\"\n",
    "\n",
    "def s3_upload_parquet_files(bucket: str = AWS_S3_BUCKET, prefix: str = AWS_S3_PREFIX, local_dir: Path = DATA_DIR) -> None:\n",
    "    \"\"\"Upload Parquet files from local directory to S3 bucket.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        bucket (str): Name of the S3 bucket.\n",
    "        prefix (str): S3 prefix (folder path) to upload files to.\n",
    "        local_dir (Path): Local directory containing Parquet files.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        region_name=\"us-west-2\",\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    )\n",
    "    for dataset_dir in DATA_DIR.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            dataset_name = dataset_dir.name\n",
    "            print(f\"Uploading dataset {dataset_name} to S3...\")\n",
    "            for root, _, files in os.walk(dataset_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".parquet\"):\n",
    "                        file_path = Path(root) / file\n",
    "                        s3_key = f\"{AWS_S3_PREFIX}{dataset_name}/{file_path.relative_to(dataset_dir)}\"\n",
    "                        print(f\"Uploading {file_path} to s3://{AWS_S3_BUCKET}/{s3_key}...\")\n",
    "                        s3_client.upload_file(\n",
    "                            Filename=str(file_path),\n",
    "                            Bucket=AWS_S3_BUCKET,\n",
    "                            Key=s3_key,\n",
    "                        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s3_upload_parquet_files(\n",
    "        bucket=AWS_S3_BUCKET,\n",
    "        prefix=AWS_S3_PREFIX,\n",
    "        local_dir=DATA_DIR,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ca2b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Download from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6f64a",
   "metadata": {},
   "source": [
    "This example demonstrates how to download Parquet files from an S3 bucket using Boto3. The example assumes the bucket you are trying to access is public. If the bucket is private, make sure you have the necessary permissions to access the specified S3 bucket and download files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "def s3_download(bucket: str, prefix: str, local_dir: str) -> None:\n",
    "    \"\"\"Download files from S3 bucket to local directory.\n",
    "\n",
    "    Args:\n",
    "        bucket (str): Name of the S3 bucket.\n",
    "        prefix (str): S3 prefix (folder path) to download files from.\n",
    "        local_dir (str): Local directory to save downloaded files.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client(\"s3\", region_name=\"us-west-2\")\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            if key.endswith(\"/\"):\n",
    "                continue\n",
    "            local_path = os.path.join(local_dir, key)\n",
    "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "            print(f\"Downloading {key} -> {local_path}\")\n",
    "            s3.download_file(bucket, key, local_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s3_download(\n",
    "        bucket=\"phyto-indicator\",\n",
    "        prefix=\"data/\",\n",
    "        local_dir=\"./local-dir\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phytoplankton-indicator-phase2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
